(()=>{var n={571:()=>{function n(t){if(!(t instanceof Map))return t;let e={};return payload.forEach(((t,r)=>{e[r]=n(t)})),e}self.fetch_bridge=async function(t,e,r){e=n(e);try{const n=await fetch(t,e);return[!1,await n.text()]}catch(n){return[!0,n]}}}},t={};function e(r){var i=t[r];if(void 0!==i)return i.exports;var a=t[r]={exports:{}};return n[r](a,a.exports,e),a.exports}(()=>{"use strict";function n(){return self.secret}self.secret="",self.org="",self.get_openai_secret=n,self.set_openai_secret=function(n){self.secret=n},self.get_openai_organization=function(){return self.org},self.set_openai_organization=function(n){self.org=n},self.openai_completion_create=async function(t,e,r){const i=(await fetch(t,{method:"POST",headers:{"Content-Type":"application/json",Authorization:"Bearer "+n()},body:e})).body.getReader(),a=new TextDecoder("utf-8");let s="<start>";for(;"<start>"==s||!s.done;){s=await i.read();let n=a.decode(s.value);await r(!1,n)}await r(!0,null)},e(571),importScripts("https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js");let t=null,r=null;function i(n){postMessage({type:"app-result",data:n})}function a(n,t){postMessage({type:"app-status",data:{status:n,error:t}})}!async function(){i("Initializing LMQL browser environment..."),a("init","python"),t=await loadPyodide({stdout:i,stderr:i}),r&&t.setInterruptBuffer(r),await async function(){a("init","libraries"),await t.loadPackage("micropip"),a("init","micropip");const n=t.runPython("import micropip; micropip");await n.install(["requests","pyyaml","filelock","regex","importlib_metadata","sacremoses","typing_extensions","ssl"]),a("init","standard libraries"),await t.loadPackage(["wheels/astunparse-1.6.3-py2.py3-none-any.whl","six","packaging","numpy","tqdm","termcolor"]),a("init","LMQL distribution"),await t.runPythonAsync('\n        from pyodide.http import pyfetch\n\n        response = await pyfetch("wheels/openai-shim.tar.gz")\n        await response.unpack_archive() # by default, unpacks to the current dir\n\n        response = await pyfetch("wheels/gpt3-tokenizer.zip")\n        await response.unpack_archive() # by default, unpacks to the current dir\n        \n        response = await pyfetch("wheels/lmql.tar.gz")\n        await response.unpack_archive() # by default, unpacks to the current dir\n        \n        import sys\n        import os\n        sys.path.append(os.path.join(os.getcwd(), "lmql/ui/live"))\n\n        try:\n            # set USE_TORCH to true\n            os.environ["USE_TORCH"] = "1"\n            os.environ["LMQL_BROWSER"] = "1"\n            os.environ["SLOW_TOKENIZER_OK"] = "1"\n            import lmql\n            print("LMQL", lmql.__version__, "on Pyodide Python", sys.version)\n            # open and print lmql package folder BUILD\n            with open(os.path.join(os.path.dirname(os.path.dirname(lmql.__file__)), "BUILD")) as f:\n                print("BUILD_INFO", f.read())\n        except Exception as e:\n            print("Failed", e)\n            # print stacktrace of \n            import traceback\n            traceback.print_exc()\n        os.chdir("lmql/ui/")\n    '),a("idle",null)}()}(),self.run=async function(n){a("running",null);const e=await t.runPythonAsync('\nimport lmql\nimport json\nimport asyncio\nfrom lmql.runtime.output_writer import BaseOutputWriter\n\nclass EventStreamOutputWriter(BaseOutputWriter):\n    def __init__(self):\n        super().__init__(allows_input=False)\n    \n    async def add_interpreter_head_state(self, variable, head, prompt, where, trace, is_valid, is_final, mask, num_tokens, program_variables):\n        chunk = f"{json.dumps({\'prompt\': prompt, \'variables\': program_variables.variable_values})}"\n        print(chunk, flush=True)\n\nprint("here", flush=True)\n\nasync def cli(args):\n    print("args", args, flush=True)\n    query = args[0]\n    try:\n        result = await lmql.run(query, output_writer=EventStreamOutputWriter())\n        print("result", result, flush=True)\n        return result\n    except InterruptedError:\n        print("APP EXIT App exited with status 1")\n        return None\n    except KeyboardInterrupt:\n        print("APP EXIT App exited with status 1")\n        return None\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        print("APP ERROR App exited with status 1")\n        raise e\ncli\n');try{await e(t.toPy(n))}finally{a("idle",null)}},self.live=async function(n){a("running",null);const e=await t.runPythonAsync('\nimport lmql.ui.live.live as lmql_live\nimport json\nimport asyncio\n\nasync def cli(args):\n    for i in range(1, len(args)):\n        args[i] = json.dumps(args[i])\n    args = ["web"] + args\n\n    try:\n        return await lmql_live.LiveApp.async_cli(args)\n    except InterruptedError:\n        print("APP EXIT App exited with status 1")\n        return None\n    except KeyboardInterrupt:\n        print("APP EXIT App exited with status 1")\n        return None\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        print("APP ERROR App exited with status 1")\n        raise e\ncli\n');try{await e(t.toPy(n))}finally{a("idle",null)}},self.send_input=async function(n){const e=await t.runPythonAsync("\nimport lmql.ui.live.live as lmql_live\nasync def send_input(s):\n    try:\n        r = await lmql_live.LiveApp.send_input(s)\n        return r\n    except Exception as e:\n        print(e)\nsend_input\n");try{await e(t.toPy(n))}catch(n){console.error("Error sending input",n)}},self.set_interrupt_buffer=async function(n){t?(t.setInterruptBuffer(n),r=n):r=n},self.kill=async function(){console.log("Kill via LMQL interrupt"),t.runPython("\nfrom lmql.runtime.interrupt import interrupt\ninterrupt.set()\n")},self.onmessage=async function(n){let t=n.data.func;if(self[t])try{await self[t](n.data.args)}catch(n){console.error("Error in worker function",t,n)}else console.error("Unknown worker function",t)}})()})();